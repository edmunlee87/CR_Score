{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b87041e5",
   "metadata": {},
   "source": [
    "# CR_Score Playbook 01: Quick Start\n",
    "\n",
    "**Level:** Beginner  \n",
    "**Time:** 5-10 minutes  \n",
    "**Goal:** Build your first credit scorecard in 3 lines of code\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- Load credit application data\n",
    "- Build a complete scorecard in 3 lines\n",
    "- Evaluate model performance\n",
    "- Score new applications\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Python 3.9+\n",
    "- CR_Score installed (`pip install -e .` from project root)\n",
    "- No PySpark required!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f22ffe",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Load Data\n",
    "\n",
    "First, let's import the necessary libraries and load our sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8cc684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root / 'src'))\n",
    "\n",
    "# Import CR_Score\n",
    "from cr_score import ScorecardPipeline\n",
    "\n",
    "print(\"[OK] Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a6fddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "\n",
    "print(f\"Training data: {len(train_df)} applications\")\n",
    "print(f\"Default rate: {train_df['default'].mean()*100:.2f}%\")\n",
    "print(f\"\\nFeatures: {train_df.shape[1]} columns\")\n",
    "\n",
    "# Show sample\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53864606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "\n",
    "print(f\"Test data: {len(test_df)} applications\")\n",
    "print(f\"Default rate: {test_df['default'].mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1259ea",
   "metadata": {},
   "source": [
    "## Step 2: Build Scorecard in 3 Lines!\n",
    "\n",
    "This is where the magic happens. CR_Score makes it incredibly simple to build a complete scorecard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b42308c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LINE 1: Create pipeline\n",
    "pipeline = ScorecardPipeline(\n",
    "    max_n_bins=5,        # Maximum 5 bins per feature\n",
    "    pdo=20,              # Every 20 points, odds double\n",
    "    base_score=600       # Score 600 = 2% default rate\n",
    ")\n",
    "\n",
    "# LINE 2: Train on data\n",
    "pipeline.fit(train_df, target_col='default')\n",
    "\n",
    "# LINE 3: Predict scores\n",
    "scores = pipeline.predict(test_df)\n",
    "\n",
    "print(\"[OK] Scorecard built and scores predicted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcca9dc",
   "metadata": {},
   "source": [
    "## Step 3: Understand the Results\n",
    "\n",
    "Let's see what our scorecard produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9400902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score statistics\n",
    "print(\"Score Statistics:\")\n",
    "print(f\"  Mean:   {scores.mean():.0f}\")\n",
    "print(f\"  Median: {np.median(scores):.0f}\")\n",
    "print(f\"  Min:    {scores.min():.0f}\")\n",
    "print(f\"  Max:    {scores.max():.0f}\")\n",
    "print(f\"  Std:    {scores.std():.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b9a171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot score distribution\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Separate by default status\n",
    "goods = scores[test_df['default'] == 0]\n",
    "bads = scores[test_df['default'] == 1]\n",
    "\n",
    "plt.hist(goods, bins=30, alpha=0.6, label='Good (no default)', color='green')\n",
    "plt.hist(bads, bins=30, alpha=0.6, label='Bad (default)', color='red')\n",
    "\n",
    "plt.xlabel('Credit Score')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Score Distribution by Default Status')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"Higher scores = Lower risk (good separation!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a648820e",
   "metadata": {},
   "source": [
    "## Step 4: Evaluate Performance\n",
    "\n",
    "Let's see how good our scorecard is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12441648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "metrics = pipeline.evaluate(test_df, target_col='default')\n",
    "\n",
    "print(\"Model Performance:\")\n",
    "print(f\"  AUC:   {metrics['auc']:.3f} {'(Excellent!)' if metrics['auc'] >= 0.8 else '(Good!)' if metrics['auc'] >= 0.7 else ''}\")\n",
    "print(f\"  Gini:  {metrics['gini']:.3f}\")\n",
    "print(f\"  KS:    {metrics['ks']:.3f}\")\n",
    "print(\"\\nInterpretation:\")\n",
    "print(f\"  - AUC {metrics['auc']:.3f} means the model is {'excellent' if metrics['auc'] >= 0.8 else 'good' if metrics['auc'] >= 0.7 else 'fair'}\")\n",
    "print(f\"  - It can distinguish between good and bad customers!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee71b25",
   "metadata": {},
   "source": [
    "## Step 5: See Which Features Were Selected\n",
    "\n",
    "Let's understand what the model is using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c9dbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pipeline summary\n",
    "summary = pipeline.get_summary()\n",
    "\n",
    "print(f\"Number of features selected: {summary['n_features']}\")\n",
    "print(f\"\\nSelected features:\")\n",
    "for i, feature in enumerate(summary['selected_features'], 1):\n",
    "    print(f\"  {i}. {feature}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c753101c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See feature importance (IV values)\n",
    "iv_df = pd.DataFrame(summary['iv_summary'])\n",
    "iv_df = iv_df.sort_values('iv', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance (Information Value):\")\n",
    "print(iv_df.to_string(index=False))\n",
    "\n",
    "print(\"\\nIV Interpretation:\")\n",
    "print(\"  < 0.02: Weak\")\n",
    "print(\"  0.02-0.1: Medium\")\n",
    "print(\"  0.1-0.3: Strong\")\n",
    "print(\"  > 0.3: Very Strong\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d194f11",
   "metadata": {},
   "source": [
    "## Step 6: Score New Applications\n",
    "\n",
    "Now let's use our scorecard to score new loan applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e640c5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take first 10 applications from test set as \"new\" applications\n",
    "new_applications = test_df.head(10).copy()\n",
    "\n",
    "# Score them\n",
    "new_scores = pipeline.predict(new_applications)\n",
    "new_probas = pipeline.predict_proba(new_applications)\n",
    "\n",
    "# Add to dataframe\n",
    "new_applications['credit_score'] = new_scores\n",
    "new_applications['default_probability'] = new_probas\n",
    "\n",
    "# Show results\n",
    "display_cols = ['application_id', 'age', 'income', 'debt_to_income_ratio', \n",
    "                'credit_score', 'default_probability', 'default']\n",
    "\n",
    "print(\"New Application Scores:\")\n",
    "print(new_applications[display_cols].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6c2d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make decisions based on scores\n",
    "def make_decision(score):\n",
    "    if score >= 650:\n",
    "        return 'APPROVE'\n",
    "    elif score >= 600:\n",
    "        return 'REVIEW'\n",
    "    else:\n",
    "        return 'DECLINE'\n",
    "\n",
    "new_applications['decision'] = new_applications['credit_score'].apply(make_decision)\n",
    "\n",
    "print(\"\\nDecisions:\")\n",
    "decision_cols = ['application_id', 'credit_score', 'decision', 'default']\n",
    "print(new_applications[decision_cols].to_string(index=False))\n",
    "\n",
    "print(\"\\nDecision Summary:\")\n",
    "print(new_applications['decision'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394b60ed",
   "metadata": {},
   "source": [
    "## Step 7: Save Your Scorecard\n",
    "\n",
    "Let's save the scorecard for production use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f43470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save pipeline\n",
    "import pickle\n",
    "\n",
    "with open('my_first_scorecard.pkl', 'wb') as f:\n",
    "    pickle.dump(pipeline, f)\n",
    "\n",
    "print(\"[OK] Scorecard saved to 'my_first_scorecard.pkl'\")\n",
    "\n",
    "# You can load it later like this:\n",
    "# with open('my_first_scorecard.pkl', 'rb') as f:\n",
    "#     loaded_pipeline = pickle.load(f)\n",
    "#     scores = loaded_pipeline.predict(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca05a10",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Congratulations! You just built your first credit scorecard in 3 lines of code!\n",
    "\n",
    "### What You Did:\n",
    "\n",
    "1. Loaded credit application data\n",
    "2. Built a complete scorecard in 3 lines\n",
    "3. Evaluated performance (AUC, Gini, KS)\n",
    "4. Understood which features are important\n",
    "5. Scored new applications\n",
    "6. Made approve/decline decisions\n",
    "7. Saved the scorecard for production\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- **Playbook 02**: Learn feature selection to pick the best features\n",
    "- **Playbook 03**: Create beautiful visualizations and reports\n",
    "- **Playbook 04**: Master the complete scorecard workflow\n",
    "- **Playbook 05**: Explore advanced topics\n",
    "\n",
    "### Key Takeaway:\n",
    "\n",
    "CR_Score makes scorecard development **simple** without sacrificing **power**. You got enterprise-grade results with beginner-friendly code!"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
