{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e04983a",
   "metadata": {},
   "source": [
    "# CR_Score Playbook 04: Complete Workflow\n",
    "\n",
    "**Level:** Intermediate  \n",
    "**Time:** 25-30 minutes  \n",
    "**Goal:** Master the end-to-end scorecard development process\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- Complete 10-step scorecard workflow\n",
    "- Data validation and EDA\n",
    "- Optimal binning\n",
    "- WoE encoding\n",
    "- Model training and evaluation\n",
    "- Calibration and scaling\n",
    "- Production deployment\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Completed Playbooks 01-03"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5731359d",
   "metadata": {},
   "source": [
    "## Complete 10-Step Workflow\n",
    "\n",
    "This notebook shows the COMPLETE manual workflow. Compare this to the 3-line approach in Playbook 01!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d229019",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root / 'src'))\n",
    "\n",
    "from cr_score.data.validation import DataQualityChecker\n",
    "from cr_score.eda import UnivariateAnalyzer, BivariateAnalyzer\n",
    "from cr_score.binning import OptBinningWrapper\n",
    "from cr_score.encoding import WoEEncoder\n",
    "from cr_score.features import StepwiseSelector\n",
    "from cr_score.model import LogisticScorecard\n",
    "from cr_score.calibration import InterceptCalibrator\n",
    "from cr_score.scaling import PDOScaler\n",
    "\n",
    "print(\"[OK] All modules imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234daebe",
   "metadata": {},
   "source": [
    "## Step 1: Load and Validate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bee59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "\n",
    "print(f\"Data loaded: {len(train_df)} train, {len(test_df)} test\")\n",
    "\n",
    "# Data quality checks\n",
    "dq_checker = DataQualityChecker()\n",
    "dq_results = dq_checker.check(train_df)\n",
    "\n",
    "print(f\"\\nData Quality:\")\n",
    "print(f\"  Missing values: {dq_results['missing_count']}\")\n",
    "print(f\"  Duplicates: {dq_results['duplicate_count']}\")\n",
    "print(\"[OK] Data validation passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac0c8b8",
   "metadata": {},
   "source": [
    "## Step 2: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ce4c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate analysis\n",
    "uni_analyzer = UnivariateAnalyzer()\n",
    "uni_results = uni_analyzer.analyze(train_df, target='default')\n",
    "\n",
    "print(\"Feature Statistics:\")\n",
    "for feat, stats in list(uni_results.items())[:3]:\n",
    "    print(f\"  {feat}: mean={stats.get('mean', 'N/A')}\")\n",
    "\n",
    "print(\"[OK] EDA completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eab4108",
   "metadata": {},
   "source": [
    "## Step 3-9: Binning, Encoding, Selection, Modeling, Calibration, Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7769457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For brevity, we'll use the pipeline (which does all these steps)\n",
    "# See the actual implementation in each module for details\n",
    "\n",
    "from cr_score import ScorecardPipeline\n",
    "\n",
    "pipeline = ScorecardPipeline(max_n_bins=5, pdo=20, base_score=600)\n",
    "pipeline.fit(train_df, target_col='default')\n",
    "\n",
    "print(\"[OK] Steps 3-9 completed via pipeline!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6226a9",
   "metadata": {},
   "source": [
    "## Step 10: Evaluate and Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1bffcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "metrics = pipeline.evaluate(test_df, target_col='default')\n",
    "\n",
    "print(\"Final Performance:\")\n",
    "print(f\"  AUC:  {metrics['auc']:.3f}\")\n",
    "print(f\"  Gini: {metrics['gini']:.3f}\")\n",
    "print(f\"  KS:   {metrics['ks']:.3f}\")\n",
    "\n",
    "# Save for production\n",
    "import pickle\n",
    "with open('production_scorecard.pkl', 'wb') as f:\n",
    "    pickle.dump(pipeline, f)\n",
    "\n",
    "print(\"\\n[OK] Scorecard ready for production!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987495fd",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You mastered the complete 10-step workflow:\n",
    "1. Data Loading\n",
    "2. Data Validation\n",
    "3. EDA\n",
    "4. Optimal Binning\n",
    "5. WoE Encoding\n",
    "6. Feature Selection\n",
    "7. Model Training\n",
    "8. Calibration\n",
    "9. PDO Scaling\n",
    "10. Evaluation & Deployment\n",
    "\n",
    "**Next:** Playbook 05 for advanced production features!"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
