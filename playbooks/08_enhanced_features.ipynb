{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhanced Feature Engineering Playbook\n",
    "\n",
    "This notebook demonstrates the enhanced feature engineering capabilities including:\n",
    "- Temporal trend features\n",
    "- Categorical encoding  \n",
    "- Feature validation\n",
    "- Dependency management\n",
    "- Feature metadata & lineage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from cr_score.features import (\n",
    "    # Core engineering\n",
    "    FeatureRecipe,\n",
    "    FeatureEngineeringConfig,\n",
    "    PandasFeatureEngineer,\n",
    "    AggregationType,\n",
    "    TimeWindow,\n",
    "    FeatureRegistry,\n",
    "    # Enhanced features\n",
    "    TemporalTrendFeatures,\n",
    "    CategoricalEncoder,\n",
    "    FeatureValidator,\n",
    "    DependencyGraph,\n",
    ")\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Sample Credit Bureau Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample customer-month level data\n",
    "np.random.seed(42)\n",
    "\n",
    "customers = [f\"CUST_{i:04d}\" for i in range(1, 21)]  # 20 customers\n",
    "months = pd.date_range('2023-01-01', '2023-12-31', freq='M')  # 12 months\n",
    "\n",
    "data = []\n",
    "for customer in customers:\n",
    "    for month in months:\n",
    "        data.append({\n",
    "            'customer_id': customer,\n",
    "            'snapshot_date': month,\n",
    "            'balance': np.random.randint(500, 10000),\n",
    "            'credit_limit': np.random.randint(5000, 20000),\n",
    "            'days_past_due': np.random.choice([0, 0, 0, 0, 0, 0, 0, 15, 30, 60, 90], p=[0.7, 0.1, 0.05, 0.05, 0.05, 0.02, 0.01, 0.01, 0.005, 0.003, 0.002]),\n",
    "            'payment_amount': np.random.randint(100, 2000),\n",
    "            'num_inquiries': np.random.randint(0, 5),\n",
    "            'num_accounts': np.random.randint(1, 10),\n",
    "            'total_debt': np.random.randint(1000, 50000),\n",
    "            'account_type': np.random.choice(['Credit Card', 'Personal Loan', 'Auto Loan', 'Mortgage']),\n",
    "            'region': np.random.choice(['North', 'South', 'East', 'West']),\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(f\"Created dataset with {len(df)} rows\")\n",
    "print(f\"Customers: {df['customer_id'].nunique()}\")\n",
    "print(f\"Date range: {df['snapshot_date'].min()} to {df['snapshot_date'].max()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Temporal Trend Features\n",
    "\n",
    "Create time-based features like delta, percent change, momentum, volatility, and trend slope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend = TemporalTrendFeatures()\n",
    "\n",
    "# Delta (change from previous period)\n",
    "df = trend.delta(\n",
    "    df,\n",
    "    column='balance',\n",
    "    time_col='snapshot_date',\n",
    "    group_cols=['customer_id']\n",
    ")\n",
    "\n",
    "# Percent change\n",
    "df = trend.pct_change(\n",
    "    df,\n",
    "    column='balance',\n",
    "    time_col='snapshot_date',\n",
    "    group_cols=['customer_id']\n",
    ")\n",
    "\n",
    "# Momentum (current - rolling mean)\n",
    "df = trend.momentum(\n",
    "    df,\n",
    "    column='balance',\n",
    "    time_col='snapshot_date',\n",
    "    group_cols=['customer_id'],\n",
    "    window=3\n",
    ")\n",
    "\n",
    "# Volatility\n",
    "df = trend.volatility(\n",
    "    df,\n",
    "    column='balance',\n",
    "    time_col='snapshot_date',\n",
    "    group_cols=['customer_id'],\n",
    "    window=6,\n",
    "    method='std'\n",
    ")\n",
    "\n",
    "# Trend slope\n",
    "df = trend.trend_slope(\n",
    "    df,\n",
    "    column='balance',\n",
    "    time_col='snapshot_date',\n",
    "    group_cols=['customer_id'],\n",
    "    window=6\n",
    ")\n",
    "\n",
    "print(\"✓ Created temporal trend features\")\n",
    "print(\"\\nNew columns:\")\n",
    "trend_cols = [c for c in df.columns if any(x in c for x in ['delta', 'pct_change', 'momentum', 'volatility', 'slope'])]\n",
    "print(trend_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize temporal features for a sample customer\n",
    "sample_customer = df['customer_id'].iloc[0]\n",
    "customer_data = df[df['customer_id'] == sample_customer].sort_values('snapshot_date')\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(15, 12))\n",
    "fig.suptitle(f'Temporal Features for {sample_customer}', fontsize=16)\n",
    "\n",
    "# Balance over time\n",
    "axes[0, 0].plot(customer_data['snapshot_date'], customer_data['balance'], marker='o')\n",
    "axes[0, 0].set_title('Balance Over Time')\n",
    "axes[0, 0].set_xlabel('Date')\n",
    "axes[0, 0].set_ylabel('Balance')\n",
    "\n",
    "# Delta\n",
    "axes[0, 1].plot(customer_data['snapshot_date'], customer_data['balance_delta'], marker='o', color='orange')\n",
    "axes[0, 1].set_title('Balance Delta')\n",
    "axes[0, 1].set_xlabel('Date')\n",
    "axes[0, 1].axhline(y=0, color='r', linestyle='--', alpha=0.3)\n",
    "\n",
    "# Percent Change\n",
    "axes[1, 0].plot(customer_data['snapshot_date'], customer_data['balance_pct_change'], marker='o', color='green')\n",
    "axes[1, 0].set_title('Balance % Change')\n",
    "axes[1, 0].set_xlabel('Date')\n",
    "axes[1, 0].axhline(y=0, color='r', linestyle='--', alpha=0.3)\n",
    "\n",
    "# Momentum\n",
    "axes[1, 1].plot(customer_data['snapshot_date'], customer_data['balance_momentum_3'], marker='o', color='purple')\n",
    "axes[1, 1].set_title('Balance Momentum (3-period)')\n",
    "axes[1, 1].set_xlabel('Date')\n",
    "axes[1, 1].axhline(y=0, color='r', linestyle='--', alpha=0.3)\n",
    "\n",
    "# Volatility\n",
    "axes[2, 0].plot(customer_data['snapshot_date'], customer_data['balance_volatility_6'], marker='o', color='red')\n",
    "axes[2, 0].set_title('Balance Volatility (6-period)')\n",
    "axes[2, 0].set_xlabel('Date')\n",
    "\n",
    "# Trend Slope\n",
    "axes[2, 1].plot(customer_data['snapshot_date'], customer_data['balance_trend_slope_6'], marker='o', color='brown')\n",
    "axes[2, 1].set_title('Balance Trend Slope (6-period)')\n",
    "axes[2, 1].set_xlabel('Date')\n",
    "axes[2, 1].axhline(y=0, color='r', linestyle='--', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Categorical Encoding\n",
    "\n",
    "Encode categorical variables using frequency, target mean, and rare grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a target variable (default indicator)\n",
    "df['is_default'] = (df['days_past_due'] > 30).astype(int)\n",
    "\n",
    "encoder = CategoricalEncoder()\n",
    "\n",
    "# Frequency encoding\n",
    "df = encoder.freq_encoding(df, 'account_type')\n",
    "df = encoder.freq_encoding(df, 'region')\n",
    "\n",
    "# Target mean encoding\n",
    "df = encoder.target_mean_encoding(\n",
    "    df,\n",
    "    column='account_type',\n",
    "    target='is_default',\n",
    "    smoothing=5.0\n",
    ")\n",
    "\n",
    "# Rare grouping\n",
    "df = encoder.rare_grouping(\n",
    "    df,\n",
    "    column='region',\n",
    "    threshold=0.15\n",
    ")\n",
    "\n",
    "print(\"✓ Created categorical encodings\")\n",
    "print(\"\\nEncoding mappings:\")\n",
    "for name, mapping in encoder.mappings.items():\n",
    "    print(f\"  {name}: {mapping['type']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize categorical encodings\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Account type frequency\n",
    "df.groupby('account_type')['account_type_freq'].first().plot(kind='bar', ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Account Type Frequency Encoding')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Account type target mean\n",
    "df.groupby('account_type')['account_type_target_mean'].first().plot(kind='bar', ax=axes[0, 1], color='orange')\n",
    "axes[0, 1].set_title('Account Type Target Mean Encoding')\n",
    "axes[0, 1].set_ylabel('Target Mean')\n",
    "\n",
    "# Region frequency\n",
    "df.groupby('region')['region_freq'].first().plot(kind='bar', ax=axes[1, 0], color='green')\n",
    "axes[1, 0].set_title('Region Frequency Encoding')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Region grouping\n",
    "df['region_grouped'].value_counts().plot(kind='bar', ax=axes[1, 1], color='purple')\n",
    "axes[1, 1].set_title('Region Rare Grouping')\n",
    "axes[1, 1].set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Validation\n",
    "\n",
    "Validate features and check for data quality issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define thresholds\n",
    "validator = FeatureValidator(\n",
    "    warning_thresholds={'missing_rate': 0.05, 'zero_variance': True},\n",
    "    hard_fail_thresholds={'missing_rate': 0.20}\n",
    ")\n",
    "\n",
    "# Validate numeric features\n",
    "numeric_features = ['balance', 'credit_limit', 'days_past_due', 'payment_amount', \n",
    "                   'balance_delta', 'balance_pct_change', 'balance_momentum_3']\n",
    "\n",
    "results = validator.validate_features(df, feature_list=numeric_features)\n",
    "\n",
    "# Convert to DataFrame for better visualization\n",
    "validation_df = validator.to_dataframe()\n",
    "print(\"\\nValidation Results:\")\n",
    "print(validation_df[['feature', 'missing_rate', 'mean', 'std', 'min', 'max', 'status']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize validation metrics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Missing rates\n",
    "validation_df.plot(x='feature', y='missing_rate', kind='bar', ax=axes[0, 0], legend=False)\n",
    "axes[0, 0].set_title('Missing Rate by Feature')\n",
    "axes[0, 0].set_ylabel('Missing Rate')\n",
    "axes[0, 0].axhline(y=0.05, color='orange', linestyle='--', label='Warning')\n",
    "axes[0, 0].axhline(y=0.20, color='red', linestyle='--', label='Hard Fail')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Unique counts\n",
    "validation_df.plot(x='feature', y='unique_count', kind='bar', ax=axes[0, 1], legend=False, color='green')\n",
    "axes[0, 1].set_title('Unique Count by Feature')\n",
    "axes[0, 1].set_ylabel('Unique Count')\n",
    "\n",
    "# Mean values\n",
    "validation_df.plot(x='feature', y='mean', kind='bar', ax=axes[1, 0], legend=False, color='orange')\n",
    "axes[1, 0].set_title('Mean by Feature')\n",
    "axes[1, 0].set_ylabel('Mean')\n",
    "\n",
    "# Standard deviation\n",
    "validation_df.plot(x='feature', y='std', kind='bar', ax=axes[1, 1], legend=False, color='purple')\n",
    "axes[1, 1].set_title('Standard Deviation by Feature')\n",
    "axes[1, 1].set_ylabel('Std Dev')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Dependency Graph Management\n",
    "\n",
    "Build and resolve feature dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dependency graph\n",
    "graph = DependencyGraph()\n",
    "\n",
    "# Define features and dependencies\n",
    "graph.add_feature('balance', [])\n",
    "graph.add_feature('credit_limit', [])\n",
    "graph.add_feature('utilization', ['balance', 'credit_limit'])\n",
    "graph.add_feature('log_utilization', ['utilization'])\n",
    "graph.add_feature('balance_delta', ['balance'])\n",
    "graph.add_feature('momentum', ['balance_delta'])\n",
    "\n",
    "# Get execution order\n",
    "execution_order = graph.topological_sort()\n",
    "\n",
    "print(\"\\nFeature Execution Order:\")\n",
    "for i, feature in enumerate(execution_order, 1):\n",
    "    deps = graph.get_dependencies(feature)\n",
    "    print(f\"{i}. {feature:20s} (depends on: {', '.join(deps) if deps else 'none'})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cycle detection\n",
    "try:\n",
    "    bad_graph = DependencyGraph()\n",
    "    bad_graph.add_feature('feature_a', ['feature_b'])\n",
    "    bad_graph.add_feature('feature_b', ['feature_c'])\n",
    "    bad_graph.add_feature('feature_c', ['feature_a'])  # Creates cycle\n",
    "    \n",
    "    bad_graph.topological_sort()\n",
    "except ValueError as e:\n",
    "    print(f\"\\n✓ Cycle detected correctly: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Registry & Lineage\n",
    "\n",
    "Track feature metadata and lineage for audit purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature registry\n",
    "registry = FeatureRegistry()\n",
    "\n",
    "# Register features\n",
    "registry.register(\n",
    "    name='balance_delta',\n",
    "    source_columns=['balance'],\n",
    "    operation='delta',\n",
    "    parameters={'periods': 1},\n",
    "    window=None,\n",
    "    missing_strategy='keep',\n",
    "    dependencies=[],\n",
    "    engine='pandas',\n",
    "    output_dtype='float64'\n",
    ")\n",
    "\n",
    "registry.register(\n",
    "    name='utilization',\n",
    "    source_columns=['balance', 'credit_limit'],\n",
    "    operation='ratio',\n",
    "    parameters={},\n",
    "    window=None,\n",
    "    missing_strategy='zero',\n",
    "    dependencies=[],\n",
    "    engine='pandas',\n",
    "    output_dtype='float64'\n",
    ")\n",
    "\n",
    "registry.register(\n",
    "    name='log_utilization',\n",
    "    source_columns=['utilization'],\n",
    "    operation='log',\n",
    "    parameters={'add_one': True},\n",
    "    window=None,\n",
    "    missing_strategy='keep',\n",
    "    dependencies=['utilization'],\n",
    "    engine='pandas',\n",
    "    output_dtype='float64'\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Registered 3 features\")\n",
    "print(\"\\nFeature Registry:\")\n",
    "for name, metadata in registry.features.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Sources: {metadata.source_columns}\")\n",
    "    print(f\"  Operation: {metadata.operation}\")\n",
    "    print(f\"  Dependencies: {metadata.dependencies}\")\n",
    "    print(f\"  Created: {metadata.created_timestamp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get lineage for a feature\n",
    "lineage = registry.get_lineage('log_utilization')\n",
    "print(\"\\nLineage for 'log_utilization':\")\n",
    "import json\n",
    "print(json.dumps(lineage, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Complete Feature Engineering Pipeline\n",
    "\n",
    "Put it all together in a complete pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define comprehensive feature set\n",
    "recipes = [\n",
    "    # Aggregations\n",
    "    FeatureRecipe(\"max_dpd_3m\", \"days_past_due\", AggregationType.MAX, TimeWindow.LAST_3M),\n",
    "    FeatureRecipe(\"avg_balance_6m\", \"balance\", AggregationType.MEAN, TimeWindow.LAST_6M),\n",
    "    \n",
    "    # Ratios\n",
    "    FeatureRecipe(\"utilization\", [\"balance\", \"credit_limit\"], \"ratio\"),\n",
    "    FeatureRecipe(\"debt_per_account\", [\"total_debt\", \"num_accounts\"], \"ratio\"),\n",
    "    \n",
    "    # Transformations\n",
    "    FeatureRecipe(\"log_debt\", \"total_debt\", \"log\", params={\"add_one\": True}),\n",
    "]\n",
    "\n",
    "config = FeatureEngineeringConfig(\n",
    "    recipes=recipes,\n",
    "    id_col=\"customer_id\",\n",
    "    time_col=\"snapshot_date\",\n",
    "    group_cols=[\"customer_id\"]\n",
    ")\n",
    "\n",
    "engineer = PandasFeatureEngineer(config)\n",
    "df_features = engineer.fit_transform(df)\n",
    "\n",
    "print(f\"\\n✓ Created {len(engineer.created_features_)} features via pipeline\")\n",
    "print(f\"\\nFeatures: {engineer.created_features_}\")\n",
    "print(f\"\\nSample output:\")\n",
    "print(df_features[['customer_id'] + engineer.created_features_].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary\n",
    "\n",
    "This playbook demonstrated:\n",
    "\n",
    "1. **Temporal Trend Features**: delta, percent change, momentum, volatility, trend slope\n",
    "2. **Categorical Encoding**: frequency, target mean, rare grouping\n",
    "3. **Feature Validation**: Quality metrics, thresholds, PSI\n",
    "4. **Dependency Management**: Topological sort, cycle detection\n",
    "5. **Feature Registry**: Metadata tracking, lineage, audit trail\n",
    "6. **Complete Pipeline**: Integration with existing feature engineering\n",
    "\n",
    "All features are production-ready and integrate seamlessly with CR-Score pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Enhanced Feature Engineering Playbook Complete!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
