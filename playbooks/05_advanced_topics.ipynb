{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27c57ad8",
   "metadata": {},
   "source": [
    "# CR_Score Playbook 05: Advanced Topics\n",
    "\n",
    "**Level:** Advanced  \n",
    "**Time:** 30-40 minutes  \n",
    "**Goal:** Master enterprise-grade production features\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- Config-driven development (YAML)\n",
    "- Spark-based compression (optional)\n",
    "- Reject inference\n",
    "- Drift detection\n",
    "- MCP tools for AI agents\n",
    "- Artifact versioning\n",
    "- Production patterns\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Completed Playbooks 01-04\n",
    "- PySpark installed (optional): `pip install pyspark>=3.4.0`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641ef9a8",
   "metadata": {},
   "source": [
    "## Check PySpark Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffd09f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Check PySpark\n",
    "try:\n",
    "    import spark_helper\n",
    "    spark = spark_helper.get_spark_session()\n",
    "    if spark:\n",
    "        print(\"[OK] PySpark is available - full features enabled!\")\n",
    "    else:\n",
    "        print(\"[INFO] PySpark not available - some features limited\")\n",
    "except:\n",
    "    print(\"[INFO] Running without PySpark - this is fine!\")\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root / 'src'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd385de",
   "metadata": {},
   "source": [
    "## Topic 1: Config-Driven Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f058f645",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "\n",
    "# Example configuration\n",
    "config = {\n",
    "    'project': {\n",
    "        'name': 'credit_scorecard_v1',\n",
    "        'description': 'Production credit scorecard'\n",
    "    },\n",
    "    'binning': {\n",
    "        'method': 'optbinning',\n",
    "        'max_n_bins': 5,\n",
    "        'min_bin_size': 0.05\n",
    "    },\n",
    "    'model': {\n",
    "        'type': 'logistic',\n",
    "        'max_iter': 1000,\n",
    "        'solver': 'lbfgs'\n",
    "    },\n",
    "    'scaling': {\n",
    "        'pdo': 20,\n",
    "        'base_score': 600,\n",
    "        'base_odds': 50\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save config\n",
    "with open('scorecard_config.yaml', 'w') as f:\n",
    "    yaml.dump(config, f)\n",
    "\n",
    "print(\"[OK] Config-driven workflow enabled!\")\n",
    "print(\"\\nConfig:\")\n",
    "print(yaml.dump(config))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84871d05",
   "metadata": {},
   "source": [
    "## Topic 2: Reject Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e363db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cr_score.reject_inference import ParcelingMethod, ReweightingMethod\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "\n",
    "# Simulate rejects (applications that were declined, so we don't know true outcome)\n",
    "# In reality, you'd have actual reject data\n",
    "rejects_df = train_df.sample(frac=0.2, random_state=42).copy()\n",
    "rejects_df['default'] = -1  # Unknown\n",
    "\n",
    "print(f\"Accepted: {len(train_df)} applications\")\n",
    "print(f\"Rejected: {len(rejects_df)} applications (unknown outcomes)\")\n",
    "\n",
    "# Apply parceling method\n",
    "parceling = ParcelingMethod()\n",
    "inferred_df = parceling.infer(\n",
    "    accepted_df=train_df,\n",
    "    rejected_df=rejects_df,\n",
    "    features=['age', 'income', 'debt_to_income_ratio']\n",
    ")\n",
    "\n",
    "print(f\"\\n[OK] Reject inference completed!\")\n",
    "print(f\"Inferred {len(inferred_df)} reject outcomes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094e98fc",
   "metadata": {},
   "source": [
    "## Topic 3: Drift Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b91e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cr_score.eda import DriftDetector\n",
    "\n",
    "# Simulate production data (test set as \"new\" data)\n",
    "baseline_df = pd.read_csv('data/train.csv')\n",
    "production_df = pd.read_csv('data/test.csv')\n",
    "\n",
    "# Detect drift\n",
    "drift_detector = DriftDetector()\n",
    "drift_results = drift_detector.detect_psi(\n",
    "    baseline_df=baseline_df,\n",
    "    production_df=production_df,\n",
    "    features=['age', 'income', 'debt_to_income_ratio']\n",
    ")\n",
    "\n",
    "print(\"Population Stability Index (PSI):\")\n",
    "for feat, psi in drift_results.items():\n",
    "    status = \"STABLE\" if psi < 0.1 else \"WARNING\" if psi < 0.25 else \"ALERT\"\n",
    "    print(f\"  {feat:25s}: PSI={psi:.4f} [{status}]\")\n",
    "\n",
    "print(\"\\n[OK] Drift detection completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cca2484",
   "metadata": {},
   "source": [
    "## Topic 4: MCP Tools for AI Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ca1ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cr_score.tools import mcp_tools\n",
    "\n",
    "# MCP tools enable AI agents to interact with scorecards\n",
    "print(\"Available MCP Tools:\")\n",
    "print(\"  1. score_predict_tool - Score applications\")\n",
    "print(\"  2. model_evaluate_tool - Evaluate model performance\")\n",
    "print(\"  3. feature_select_tool - Run feature selection\")\n",
    "print(\"  4. binning_analyze_tool - Analyze binning results\")\n",
    "\n",
    "print(\"\\n[OK] MCP tools ready for AI agent integration!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510c0539",
   "metadata": {},
   "source": [
    "## Topic 5: Artifact Versioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82ada19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cr_score.core.registry import ArtifactIndex, RunRegistry\n",
    "from cr_score.core.hashing import hash_content\n",
    "import json\n",
    "\n",
    "# Create artifact registry\n",
    "artifact_index = ArtifactIndex(registry_path='./artifacts')\n",
    "\n",
    "# Example: register a model artifact\n",
    "model_artifact = {\n",
    "    'artifact_id': 'model_v1',\n",
    "    'artifact_type': 'model',\n",
    "    'content_hash': hash_content({'model': 'logistic', 'version': 1}),\n",
    "    'file_path': 'production_scorecard.pkl',\n",
    "    'metadata': {\n",
    "        'auc': 0.850,\n",
    "        'created_at': '2026-01-16',\n",
    "        'author': 'Your Name'\n",
    "    }\n",
    "}\n",
    "\n",
    "artifact_index.register(model_artifact)\n",
    "\n",
    "print(\"[OK] Artifact versioning enabled!\")\n",
    "print(f\"\\nArtifact registered:\")\n",
    "print(json.dumps(model_artifact, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361a2135",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You mastered advanced production topics:\n",
    "- Config-driven development with YAML\n",
    "- Reject inference for unseen data\n",
    "- Drift detection with PSI/CSI\n",
    "- MCP tools for AI agent integration\n",
    "- Artifact versioning and lineage\n",
    "\n",
    "**Congratulations!** You've completed all CR_Score playbooks!\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "1. **Build your own scorecard** with real data\n",
    "2. **Deploy to production** using these patterns\n",
    "3. **Contribute** to the CR_Score project\n",
    "4. **Share** your learnings with the community\n",
    "\n",
    "**You're now a CR_Score expert!** ðŸŽ‰"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
